{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sankarvinayak/DL-assignment-3/blob/main/DL_Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DA6401 Assignment 3\n",
        "Use recurrent neural networks to build a transliteration system."
      ],
      "metadata": {
        "id": "9iyO4eo7ajS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions\n",
        "- The goal of this assignment is fourfold: (i) learn how to model sequence to sequence learning problems using Recurrent Neural Networks (ii) compare different cells such as vanilla RNN, LSTM and GRU (iii) understand how attention networks overcome the limitations of vanilla seq2seq models (iv) visualise the interactions between different components in a RNN based model.\n",
        "- We strongly recommend that you work on this assignment in a team of size 2. Both the members\n",
        "of the team are expected to work together (in a subsequent viva both members will be expected to answer questions, explain the code, etc).\n",
        "- Collaborations and discussions with other groups are strictly prohibited.\n",
        "- You must use Python (numpy and pandas) for your implementation.\n",
        "- You can use any and all packages from keras, pytorch, tensorflow\n",
        "- You can run the code in a jupyter notebook on colab by enabling GPUs.\n",
        "- You have to generate the report in the same format as shown below using wandb.ai. You can start by cloning this report using the clone option above. Most of the plots that we have asked for below can be (automatically) generated using the apis provided by wandb.ai. You will upload a link to this report on gradescope.\n",
        "- You also need to provide a link to your github code as shown below. Follow good software engineering practices and set up a github repo for the project on Day 1. Please do not write all code on your local machine and push everything to github on the last day. The commits in github should reflect how the code has evolved during the course of the assignment.\n",
        "- You have to check moodle regularly for updates regarding the assignment.\n"
      ],
      "metadata": {
        "id": "qgw6bhgEaljz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Problem Statement\n",
        "\n",
        "In this assignment you will experiment with the [Dakshina dataset](https://github.com/google-research-datasets/dakshina) released by Google. This dataset contains pairs of the following form:\n",
        "\n",
        "$x$.      $y$\n",
        "\n",
        "ajanabee अजनबी.\n",
        "\n",
        "i.e., a word in the native script and its corresponding transliteration in the Latin script (the way we type while chatting with our friends on WhatsApp etc). Given many such $(x_i, y_i)_{i=1}^n$ pairs your goal is to train a model $y = \\hat{f}(x)$ which takes as input a romanized string (ghar) and produces the corresponding word in Devanagari (घर).\n",
        "\n",
        "As you would realise this is the problem of mapping a sequence of characters in one language to a sequence of characters in another language. Notice that this is a scaled down version of the problem of translation where the goal is to translate a sequence of **words** in one language to a sequence of words in another language (as opposed to sequence of **characters** here).\n",
        "\n",
        "Read these blogs to understand how to build neural sequence to sequence models: [blog1](https://keras.io/examples/nlp/lstm_seq2seq/), [blog2](https://machinelearningmastery.com/define-encoder-decoder-sequence-sequence-model-neural-machine-translation-keras/)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oZy-iPloatY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "!tar -xf dakshina_dataset_v1.0.tar\n",
        "!cp -r dakshina_dataset_v1.0/ml .\n",
        "!rm -rf dakshina_dataset_v1.0\n",
        "!rm -r dakshina_dataset_v1.0.tar\n",
        "!cp ml/lexicons/* ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onPyTUOtbfIk",
        "outputId": "57164652-f709-4031-efbc-be7f344a2b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-16 06:52:16--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 192.178.218.207, 172.253.62.207, 172.253.115.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|192.178.218.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G  77.3MB/s    in 22s     \n",
            "\n",
            "2025-05-16 06:52:39 (85.3 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tqdm import tqdm\n",
        "# Paths to your data files (adjust if needed)\n",
        "path = \"/content/ml/lexicons/ml.translit.sampled.train.tsv\"\n",
        "path_val = \"/content/ml/lexicons/ml.translit.sampled.dev.tsv\"\n",
        "path_test = \"/content/ml/lexicons/ml.translit.sampled.test.tsv\"\n",
        "\n",
        "# Read the files\n",
        "df = pd.read_csv(path, sep='\\t', header=None)\n",
        "df_val = pd.read_csv(path_val, sep='\\t', header=None)\n",
        "df_test = pd.read_csv(path_test, sep='\\t', header=None)\n",
        "\n",
        "# Split into native (Malayalam) and romanized (English) columns\n",
        "malayalam_words = df[0]\n",
        "english_words = df[1]\n",
        "\n",
        "malayalam_words_val = df_val[0]\n",
        "english_words_val = df_val[1]\n",
        "\n",
        "malayalam_words_test = df_test[0]\n",
        "english_words_test = df_test[1]\n",
        "\n"
      ],
      "metadata": {
        "id": "BQlWAo4vJqKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "malayalam_words,english_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MktNed8tJ1cN",
        "outputId": "e0623bf7-eb02-4bd7-cbca-11ebb6f4121a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0             അം\n",
              " 1            അംഗ\n",
              " 2            അംഗ\n",
              " 3           അംഗം\n",
              " 4           അംഗം\n",
              "           ...   \n",
              " 58377       ഹൗസ്\n",
              " 58378       ഹർജി\n",
              " 58379       ഹർജി\n",
              " 58380    ഹർജിയിൽ\n",
              " 58381    ഹർജിയിൽ\n",
              " Name: 0, Length: 58382, dtype: object,\n",
              " 0              am\n",
              " 1            amga\n",
              " 2            anga\n",
              " 3           amgam\n",
              " 4           angam\n",
              "            ...   \n",
              " 58377       house\n",
              " 58378       harje\n",
              " 58379       harji\n",
              " 58380    harjeyil\n",
              " 58381    harjiyil\n",
              " Name: 1, Length: 58382, dtype: object)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "english_words = english_words.dropna()\n",
        "malayalam_words = malayalam_words.dropna()\n",
        "\n",
        "english_words = english_words.astype(str)\n",
        "malayalam_words = malayalam_words.astype(str)\n",
        "\n",
        "english_chars = sorted(set(\"\".join(english_words)))\n",
        "malayalam_chars = sorted(set(\"\".join(malayalam_words)))\n",
        "\n",
        "max_len_eng = max(len(w) for w in pd.concat([english_words, english_words_val, english_words_test]).dropna().astype(str))\n",
        "max_len_mal = max(len(w) for w in pd.concat([malayalam_words, malayalam_words_val, malayalam_words_test]).dropna().astype(str))\n",
        "\n",
        "print(\"English characters:\", english_chars)\n",
        "print(\"Malayalam characters:\", malayalam_chars)\n",
        "print(\"Max English word length:\", max_len_eng)\n",
        "print(\"Max Malayalam word length:\", max_len_mal)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0bc09swKX8T",
        "outputId": "00a9cc09-704f-44e0-9fc7-99f69bd02eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English characters: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "Malayalam characters: ['ം', 'ഃ', 'അ', 'ആ', 'ഇ', 'ഈ', 'ഉ', 'ഊ', 'ഋ', 'എ', 'ഏ', 'ഐ', 'ഒ', 'ഓ', 'ഔ', 'ക', 'ഖ', 'ഗ', 'ഘ', 'ങ', 'ച', 'ഛ', 'ജ', 'ഝ', 'ഞ', 'ട', 'ഠ', 'ഡ', 'ഢ', 'ണ', 'ത', 'ഥ', 'ദ', 'ധ', 'ന', 'പ', 'ഫ', 'ബ', 'ഭ', 'മ', 'യ', 'ര', 'റ', 'ല', 'ള', 'ഴ', 'വ', 'ശ', 'ഷ', 'സ', 'ഹ', 'ാ', 'ി', 'ീ', 'ു', 'ൂ', 'ൃ', 'െ', 'േ', 'ൈ', 'ൊ', 'ോ', '്', 'ൗ', 'ൺ', 'ൻ', 'ർ', 'ൽ', 'ൾ', '\\u200c']\n",
            "Max English word length: 32\n",
            "Max Malayalam word length: 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Question 1 (15 Marks)\n",
        "Build a RNN based seq2seq model which contains the following layers: (i) input layer for character embeddings (ii) one encoder RNN which sequentially encodes the input character sequence (Latin) (iii) one decoder RNN which takes the last state of the encoder as input and produces one output character at a time (Devanagari).\n",
        "\n",
        "The code should be flexible such that the dimension of the input character embeddings, the hidden states of the encoders and decoders, the cell (RNN, LSTM, GRU) and the number of layers in the encoder and decoder can be changed.\n",
        "\n",
        "(a) What is the total number of computations done by your network? (assume that the input embedding size is $m$, encoder and decoder have 1 layer each, the hidden cell state is $k$ for both the encoder and decoder, the length of the input and output sequence is the same, i.e., $T$, the size of the vocabulary is the same for the source and target language, i.e., $V$)\n",
        "\n",
        "(b) What is the total number of parameters in your network? (assume that the input embedding size is $m$, encoder and decoder have 1 layer each, the hidden cell state is $k$ for both the encoder and decoder and the length of the input and output sequence is the same, i.e., $T$, the size of the vocabulary is the same for the source and target language, i.e., $V$)\n"
      ],
      "metadata": {
        "id": "6zHBg1GiawdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Question 2 (10 Marks)\n",
        "\n",
        "You will now train your model using any one language from the [Dakshina dataset](https://github.com/google-research-datasets/dakshina) (I would suggest pick a language that you can read so that it is easy to analyse the errors). Use the standard train, dev, test set from the folder dakshina_dataset_v1.0/hi/lexicons/ (replace hi by the language of your choice)\n",
        "\n",
        "Using the sweep feature in wandb find the best hyperparameter configuration. Here are some suggestions but you are free to decide which hyperparameters you want to explore\n",
        "\n",
        "- input embedding size: 16, 32, 64, 256, ...\n",
        "- number of encoder layers: 1, 2, 3\n",
        "- number of decoder layers: 1, 2, 3\n",
        "- hidden layer size: 16, 32, 64, 256, ...\n",
        "- cell type: RNN, GRU, LSTM\n",
        "- dropout: 20%, 30% (btw, where will you add dropout? you should read up a bit on this)\n",
        "- beam search in decoder with different beam sizes:\n",
        "\n",
        "Based on your sweep please paste the following plots which are automatically generated by wandb:\n",
        "- accuracy v/s created plot (I would like to see the number of experiments you ran to get the best configuration).\n",
        "- parallel co-ordinates plot\n",
        "- correlation summary table (to see the correlation of each hyperparameter with the loss/accuracy)\n",
        "\n",
        "Also write down the hyperparameters and their values that you sweeped over. Smart strategies to reduce the number of runs while still achieving a high accuracy would be appreciated. Write down any unique strategy that you tried for efficiently searching the hyperparameters."
      ],
      "metadata": {
        "id": "rcVlhzCxazCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hidden_dim, dec_hidden_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(enc_hidden_dim + dec_hidden_dim, dec_hidden_dim)\n",
        "        self.v = nn.Linear(dec_hidden_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        src_len = encoder_outputs.size(1)\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        return torch.softmax(attention, dim=1)\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, cell_type='lstm', dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        rnn_cls = {'lstm': nn.LSTM, 'gru': nn.GRU, 'rnn': nn.RNN}[cell_type.lower()]\n",
        "        self.rnn = rnn_cls(emb_dim, hidden_dim, num_layers=n_layers,\n",
        "                           dropout=dropout if n_layers > 1 else 0, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.cell_type = cell_type.lower()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        return outputs, hidden\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hidden_dim, dec_hidden_dim, n_layers, cell_type='lstm', dropout=0.0, use_attention=True):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        rnn_cls = {'lstm': nn.LSTM, 'gru': nn.GRU, 'rnn': nn.RNN}[cell_type.lower()]\n",
        "        rnn_input_dim = emb_dim + enc_hidden_dim if use_attention else emb_dim\n",
        "        self.rnn = rnn_cls(rnn_input_dim, dec_hidden_dim, num_layers=n_layers,\n",
        "                           dropout=dropout if n_layers > 1 else 0, batch_first=True)\n",
        "        self.use_attention = use_attention\n",
        "        if use_attention:\n",
        "            self.attention = Attention(enc_hidden_dim, dec_hidden_dim)\n",
        "        self.fc_out = nn.Linear(dec_hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.cell_type = cell_type.lower()\n",
        "        self.n_layers = n_layers\n",
        "        self.dec_hidden_dim = dec_hidden_dim\n",
        "\n",
        "    def forward(self, trg, hidden, encoder_outputs, teacher_forcing=True):\n",
        "        batch_size = trg.size(0)\n",
        "        trg_len = trg.size(1)\n",
        "        outputs = []\n",
        "\n",
        "        input_t = trg[:, 0]  # Start with <sos> token\n",
        "\n",
        "        if self.cell_type == 'lstm':\n",
        "            h, c = hidden\n",
        "        else:\n",
        "            h = hidden\n",
        "            c = None\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            emb_t = self.dropout(self.embedding(input_t)).unsqueeze(1)\n",
        "            hidden_t = h[-1]\n",
        "\n",
        "            if self.use_attention:\n",
        "                attn_weights = self.attention(hidden_t, encoder_outputs)\n",
        "                context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)\n",
        "                rnn_input = torch.cat((emb_t, context), dim=2)\n",
        "            else:\n",
        "                rnn_input = emb_t\n",
        "\n",
        "            if self.cell_type == 'lstm':\n",
        "                output, (h, c) = self.rnn(rnn_input, (h, c))\n",
        "            else:\n",
        "                output, h = self.rnn(rnn_input, h)\n",
        "\n",
        "            pred = self.fc_out(output.squeeze(1))\n",
        "            outputs.append(pred.unsqueeze(1))\n",
        "\n",
        "            input_t = trg[:, t] if teacher_forcing else pred.argmax(1)\n",
        "\n",
        "        outputs = torch.cat(outputs, dim=1)\n",
        "        return outputs, (h, c) if self.cell_type == 'lstm' else h\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "        self.enc_n_layers = encoder.n_layers\n",
        "        self.dec_n_layers = decoder.n_layers\n",
        "        self.enc_hidden_dim = encoder.hidden_dim\n",
        "        self.dec_hidden_dim = decoder.dec_hidden_dim\n",
        "        self.cell_type = encoder.cell_type\n",
        "        self.different_dims = self.enc_hidden_dim != self.dec_hidden_dim\n",
        "\n",
        "        if self.different_dims:\n",
        "            self.hidden_projection = nn.Linear(self.enc_hidden_dim, self.dec_hidden_dim)\n",
        "            if self.cell_type == 'lstm':\n",
        "                self.cell_projection = nn.Linear(self.enc_hidden_dim, self.dec_hidden_dim)\n",
        "\n",
        "    def _adapt_hidden_state(self, encoder_hidden):\n",
        "        if self.cell_type == 'lstm':\n",
        "            h, c = encoder_hidden\n",
        "            if self.enc_n_layers != self.dec_n_layers:\n",
        "                if self.enc_n_layers > self.dec_n_layers:\n",
        "                    h = h[-self.dec_n_layers:]\n",
        "                    c = c[-self.dec_n_layers:]\n",
        "                else:\n",
        "                    h = torch.cat([h] + [h[-1:].clone()] * (self.dec_n_layers - self.enc_n_layers), dim=0)\n",
        "                    c = torch.cat([c] + [c[-1:].clone()] * (self.dec_n_layers - self.enc_n_layers), dim=0)\n",
        "            if self.different_dims:\n",
        "                h = self.hidden_projection(h)\n",
        "                c = self.cell_projection(c)\n",
        "            return (h, c)\n",
        "        else:\n",
        "            h = encoder_hidden\n",
        "            if self.enc_n_layers != self.dec_n_layers:\n",
        "                if self.enc_n_layers > self.dec_n_layers:\n",
        "                    h = h[-self.dec_n_layers:]\n",
        "                else:\n",
        "                    h = torch.cat([h] + [h[-1:].clone()] * (self.dec_n_layers - self.enc_n_layers), dim=0)\n",
        "            if self.different_dims:\n",
        "                h = self.hidden_projection(h)\n",
        "            return h\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing=True):\n",
        "        encoder_outputs, encoder_hidden = self.encoder(src)\n",
        "        decoder_hidden = self._adapt_hidden_state(encoder_hidden)\n",
        "        outputs, _ = self.decoder(trg, decoder_hidden, encoder_outputs, teacher_forcing=teacher_forcing)\n",
        "        return outputs\n",
        "def calculate_sequence_accuracy(preds, trg):\n",
        "    pred_tokens = preds.argmax(-1)\n",
        "    match = ((pred_tokens == trg[:, 1:]) | (trg[:, 1:] == 0)).all(dim=1)\n",
        "    return match.float().mean()\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    pbar = tqdm(iterator, desc=\"Training\", leave=False)\n",
        "    for src, trg in pbar:\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg, teacher_forcing=True)\n",
        "        loss = criterion(output.view(-1, output.shape[-1]), trg[:, 1:].reshape(-1))\n",
        "        acc = calculate_sequence_accuracy(output, trg)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        pbar.set_postfix(loss=loss.item(), acc=acc.item())\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    with torch.no_grad():\n",
        "        for src, trg in iterator:\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "            output = model(src, trg, teacher_forcing=False)\n",
        "            loss = criterion(output.view(-1, output.shape[-1]), trg[:, 1:].reshape(-1))\n",
        "            acc = calculate_sequence_accuracy(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ],
      "metadata": {
        "id": "c-3RppS18xGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_english_data():\n",
        "    train_path = \"ml.translit.sampled.train.tsv\"\n",
        "    dev_path = \"ml.translit.sampled.dev.tsv\"\n",
        "    test_path = \"ml.translit.sampled.test.tsv\"\n",
        "\n",
        "    train_data = pd.read_csv(train_path, sep='\\t', header=None, names=['malayalam', 'english', 'count'])\n",
        "    dev_data = pd.read_csv(dev_path, sep='\\t', header=None, names=['malayalam', 'english', 'count'])\n",
        "    test_data = pd.read_csv(test_path, sep='\\t', header=None, names=['malayalam', 'english', 'count'])\n",
        "\n",
        "    return train_data, dev_data, test_data\n",
        "\n",
        "def preprocess_data(train_data, dev_data, test_data, max_sequence_length=20):\n",
        "    train_data = train_data.dropna()\n",
        "    dev_data = dev_data.dropna()\n",
        "    test_data = test_data.dropna()\n",
        "\n",
        "    all_src = pd.concat([train_data['english'], dev_data['english'], test_data['english']])\n",
        "    all_trg = pd.concat([train_data['malayalam'], dev_data['malayalam'], test_data['malayalam']])\n",
        "\n",
        "    src_tokenizer = Tokenizer(char_level=True, lower=False)\n",
        "    src_tokenizer.fit_on_texts(all_src)\n",
        "\n",
        "    trg_tokenizer = Tokenizer(char_level=True, lower=False)\n",
        "    trg_tokenizer.fit_on_texts(all_trg)\n",
        "\n",
        "    # Add SOS and EOS tokens\n",
        "    sos_token = '<s>'\n",
        "    eos_token = '</s>'\n",
        "    trg_tokenizer.word_index[sos_token] = len(trg_tokenizer.word_index) + 1\n",
        "    trg_tokenizer.word_index[eos_token] = len(trg_tokenizer.word_index) + 1\n",
        "\n",
        "    def process_sequences(texts, tokenizer, max_len):\n",
        "        seq = tokenizer.texts_to_sequences(texts)\n",
        "        return pad_sequences(seq, maxlen=max_len, padding='post')\n",
        "\n",
        "    def process_target_sequences(texts, tokenizer, max_len):\n",
        "        sos = tokenizer.word_index[sos_token]\n",
        "        eos = tokenizer.word_index[eos_token]\n",
        "        seq = tokenizer.texts_to_sequences(texts)\n",
        "        seq = [[sos] + s + [eos] for s in seq]\n",
        "        return pad_sequences(seq, maxlen=max_len+2, padding='post')\n",
        "\n",
        "    X_train = process_sequences(train_data['english'], src_tokenizer, max_sequence_length)\n",
        "    y_train = process_target_sequences(train_data['malayalam'], trg_tokenizer, max_sequence_length)\n",
        "\n",
        "    X_dev = process_sequences(dev_data['english'], src_tokenizer, max_sequence_length)\n",
        "    y_dev = process_target_sequences(dev_data['malayalam'], trg_tokenizer, max_sequence_length)\n",
        "\n",
        "    X_test = process_sequences(test_data['english'], src_tokenizer, max_sequence_length)\n",
        "    y_test = process_target_sequences(test_data['malayalam'], trg_tokenizer, max_sequence_length)\n",
        "\n",
        "    return X_train, y_train, X_dev, y_dev, X_test, y_test, src_tokenizer, trg_tokenizer\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Dataset\n",
        "# -------------------------------\n",
        "class Seq2SeqDataset(Dataset):\n",
        "    def __init__(self, src, trg):\n",
        "        self.src = torch.LongTensor(src)\n",
        "        self.trg = torch.LongTensor(trg)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.src[idx], self.trg[idx]\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hidden_dim, dec_hidden_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(enc_hidden_dim + dec_hidden_dim, dec_hidden_dim)\n",
        "        self.v = nn.Linear(dec_hidden_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        src_len = encoder_outputs.size(1)\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        return torch.softmax(attention, dim=1)\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, cell_type='lstm', dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        rnn_cls = {'lstm': nn.LSTM, 'gru': nn.GRU, 'rnn': nn.RNN}[cell_type.lower()]\n",
        "        self.rnn = rnn_cls(emb_dim, hidden_dim, num_layers=n_layers,\n",
        "                           dropout=dropout if n_layers > 1 else 0, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.cell_type = cell_type.lower()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        return outputs, hidden\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hidden_dim, dec_hidden_dim, n_layers, cell_type='lstm', dropout=0.0, use_attention=True):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        rnn_cls = {'lstm': nn.LSTM, 'gru': nn.GRU, 'rnn': nn.RNN}[cell_type.lower()]\n",
        "        rnn_input_dim = emb_dim + enc_hidden_dim if use_attention else emb_dim\n",
        "        self.rnn = rnn_cls(rnn_input_dim, dec_hidden_dim, num_layers=n_layers,\n",
        "                           dropout=dropout if n_layers > 1 else 0, batch_first=True)\n",
        "        self.use_attention = use_attention\n",
        "        if use_attention:\n",
        "            self.attention = Attention(enc_hidden_dim, dec_hidden_dim)\n",
        "        self.fc_out = nn.Linear(dec_hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.cell_type = cell_type.lower()\n",
        "        self.n_layers = n_layers\n",
        "        self.dec_hidden_dim = dec_hidden_dim\n",
        "\n",
        "    def forward(self, trg, hidden, encoder_outputs, teacher_forcing=True):\n",
        "        batch_size = trg.size(0)\n",
        "        trg_len = trg.size(1)\n",
        "        outputs = []\n",
        "\n",
        "        input_t = trg[:, 0]  # Start with <sos> token\n",
        "\n",
        "        if self.cell_type == 'lstm':\n",
        "            h, c = hidden\n",
        "        else:\n",
        "            h = hidden\n",
        "            c = None\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            emb_t = self.dropout(self.embedding(input_t)).unsqueeze(1)\n",
        "            hidden_t = h[-1]\n",
        "\n",
        "            if self.use_attention:\n",
        "                attn_weights = self.attention(hidden_t, encoder_outputs)\n",
        "                context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)\n",
        "                rnn_input = torch.cat((emb_t, context), dim=2)\n",
        "            else:\n",
        "                rnn_input = emb_t\n",
        "\n",
        "            if self.cell_type == 'lstm':\n",
        "                output, (h, c) = self.rnn(rnn_input, (h, c))\n",
        "            else:\n",
        "                output, h = self.rnn(rnn_input, h)\n",
        "\n",
        "            pred = self.fc_out(output.squeeze(1))\n",
        "            outputs.append(pred.unsqueeze(1))\n",
        "\n",
        "            input_t = trg[:, t] if teacher_forcing else pred.argmax(1)\n",
        "\n",
        "        outputs = torch.cat(outputs, dim=1)\n",
        "        return outputs, (h, c) if self.cell_type == 'lstm' else h\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "        self.enc_n_layers = encoder.n_layers\n",
        "        self.dec_n_layers = decoder.n_layers\n",
        "        self.enc_hidden_dim = encoder.hidden_dim\n",
        "        self.dec_hidden_dim = decoder.dec_hidden_dim\n",
        "        self.cell_type = encoder.cell_type\n",
        "        self.different_dims = self.enc_hidden_dim != self.dec_hidden_dim\n",
        "\n",
        "        if self.different_dims:\n",
        "            self.hidden_projection = nn.Linear(self.enc_hidden_dim, self.dec_hidden_dim)\n",
        "            if self.cell_type == 'lstm':\n",
        "                self.cell_projection = nn.Linear(self.enc_hidden_dim, self.dec_hidden_dim)\n",
        "\n",
        "    def _adapt_hidden_state(self, encoder_hidden):\n",
        "        if self.cell_type == 'lstm':\n",
        "            h, c = encoder_hidden\n",
        "            if self.enc_n_layers != self.dec_n_layers:\n",
        "                if self.enc_n_layers > self.dec_n_layers:\n",
        "                    h = h[-self.dec_n_layers:]\n",
        "                    c = c[-self.dec_n_layers:]\n",
        "                else:\n",
        "                    h = torch.cat([h] + [h[-1:].clone()] * (self.dec_n_layers - self.enc_n_layers), dim=0)\n",
        "                    c = torch.cat([c] + [c[-1:].clone()] * (self.dec_n_layers - self.enc_n_layers), dim=0)\n",
        "            if self.different_dims:\n",
        "                h = self.hidden_projection(h)\n",
        "                c = self.cell_projection(c)\n",
        "            return (h, c)\n",
        "        else:\n",
        "            h = encoder_hidden\n",
        "            if self.enc_n_layers != self.dec_n_layers:\n",
        "                if self.enc_n_layers > self.dec_n_layers:\n",
        "                    h = h[-self.dec_n_layers:]\n",
        "                else:\n",
        "                    h = torch.cat([h] + [h[-1:].clone()] * (self.dec_n_layers - self.enc_n_layers), dim=0)\n",
        "            if self.different_dims:\n",
        "                h = self.hidden_projection(h)\n",
        "            return h\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing=True):\n",
        "        encoder_outputs, encoder_hidden = self.encoder(src)\n",
        "        decoder_hidden = self._adapt_hidden_state(encoder_hidden)\n",
        "        outputs, _ = self.decoder(trg, decoder_hidden, encoder_outputs, teacher_forcing=teacher_forcing)\n",
        "        return outputs\n",
        "def calculate_sequence_accuracy(preds, trg):\n",
        "    pred_tokens = preds.argmax(-1)\n",
        "    match = ((pred_tokens == trg[:, 1:]) | (trg[:, 1:] == 0)).all(dim=1)\n",
        "    return match.float().mean()\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    pbar = tqdm(iterator, desc=\"Training\", leave=False)\n",
        "    for src, trg in pbar:\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg, teacher_forcing=True)\n",
        "        loss = criterion(output.view(-1, output.shape[-1]), trg[:, 1:].reshape(-1))\n",
        "        acc = calculate_sequence_accuracy(output, trg)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        pbar.set_postfix(loss=loss.item(), acc=acc.item())\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    with torch.no_grad():\n",
        "        for src, trg in iterator:\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "            output = model(src, trg, teacher_forcing=False)\n",
        "            loss = criterion(output.view(-1, output.shape[-1]), trg[:, 1:].reshape(-1))\n",
        "            acc = calculate_sequence_accuracy(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ],
      "metadata": {
        "id": "F82exrs7cWwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes',  # or 'random' if you want to sample randomly\n",
        "    'metric': {\n",
        "        'name': 'val_loss',\n",
        "        'goal': 'minimize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'batch_size': {\n",
        "            'values': [64,128,256,512]\n",
        "        },\n",
        "        'max_sequence_length': {\n",
        "            'values': [20,30,40]\n",
        "        },\n",
        "        'emb_dim': {\n",
        "            'values': [16, 32, 64, 256,512]\n",
        "        },\n",
        "        'hidden_dim': {\n",
        "            'values': [16, 32, 64, 256,512]\n",
        "        },\n",
        "        'enc_layers': {\n",
        "            'values': [1, 2, 3,4,5]\n",
        "        },\n",
        "        'dec_layers': {\n",
        "            'values': [1, 2, 3,4,5]\n",
        "        },\n",
        "        'cell_type': {\n",
        "            'values': ['rnn', 'gru', 'lstm']\n",
        "        },\n",
        "        'dropout': {\n",
        "            'values': [0.2, 0.3,0.5,0.7]\n",
        "        },\n",
        "        'n_epochs': {\n",
        "            'values': [10,20,30]\n",
        "        },\n",
        "        'lr': {\n",
        "            'values': [0.001,0.0001]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "import wandb\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"en-ml-transliteration-wo_att\")\n"
      ],
      "metadata": {
        "id": "xzOEpuMQ9BRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_seq2seq_model_wandb(config=None):\n",
        "    # Initialize wandb\n",
        "    with wandb.init(config=config):\n",
        "        config = wandb.config\n",
        "\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Load and preprocess data\n",
        "        train_data, dev_data, test_data = load_english_data()\n",
        "        X_train, y_train, X_dev, y_dev, X_test, y_test, src_tokenizer, trg_tokenizer = preprocess_data(\n",
        "            train_data, dev_data, test_data, config.max_sequence_length)\n",
        "\n",
        "        train_loader = DataLoader(Seq2SeqDataset(X_train, y_train), batch_size=config.batch_size, shuffle=True)\n",
        "        dev_loader = DataLoader(Seq2SeqDataset(X_dev, y_dev), batch_size=config.batch_size)\n",
        "        test_loader = DataLoader(Seq2SeqDataset(X_test, y_test), batch_size=config.batch_size)\n",
        "\n",
        "        input_dim = len(src_tokenizer.word_index) + 1\n",
        "        output_dim = len(trg_tokenizer.word_index) + 1\n",
        "\n",
        "        encoder = Encoder(\n",
        "            input_dim=input_dim,\n",
        "            emb_dim=config.emb_dim,\n",
        "            hidden_dim=config.hidden_dim,\n",
        "            n_layers=config.enc_layers,\n",
        "            cell_type=config.cell_type,\n",
        "            dropout=config.dropout\n",
        "        )\n",
        "        decoder = Decoder(\n",
        "            output_dim=output_dim,\n",
        "            emb_dim=config.emb_dim,\n",
        "            enc_hidden_dim=config.hidden_dim,\n",
        "            dec_hidden_dim=config.hidden_dim,\n",
        "            n_layers=config.dec_layers,\n",
        "            cell_type=config.cell_type,\n",
        "            dropout=config.dropout,\n",
        "            use_attention=False\n",
        "        )\n",
        "\n",
        "        model = Seq2Seq(encoder, decoder).to(device)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
        "        criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "\n",
        "        for epoch in range(config.n_epochs):\n",
        "            print(f\"Epoch {epoch+1}/{config.n_epochs}\")\n",
        "            train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "            valid_loss, valid_acc = evaluate(model, dev_loader, criterion, device)\n",
        "\n",
        "            print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "            print(f\"Val Loss: {valid_loss:.4f} | Val Acc: {valid_acc:.4f}\")\n",
        "\n",
        "            wandb.log({\n",
        "                'epoch': epoch + 1,\n",
        "                'train_loss': train_loss,\n",
        "                'train_acc': train_acc,\n",
        "                'val_loss': valid_loss,\n",
        "                'val_acc': valid_acc\n",
        "            })\n",
        "        wandb.finish()\n"
      ],
      "metadata": {
        "id": "N9EEEq7u9Ffi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "wandb.agent(sweep_id, function=train_seq2seq_model_wandb)"
      ],
      "metadata": {
        "id": "1cIOhvY_9I73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Question 4 (10 Marks)\n",
        "\n",
        "You will now apply your best model on the test data (You shouldn't have used test data so far. All the above experiments should have been done using train and val data only).\n",
        "\n",
        "(a) Use the best model from your sweep and report the accuracy on the test set (the output is correct only if it exactly matches the reference output).\n",
        "\n",
        "(b) Provide sample inputs from the test data and predictions made by your best model (more marks for presenting this grid creatively). Also upload all the predictions on the test set in a folder **predictions_vanilla** on your github project.\n",
        "\n",
        "(c) Comment on the errors made by your model (simple insightful bullet points)\n",
        "\n",
        "- The model makes more errors on consonants than vowels\n",
        "- The model makes more errors on longer sequences\n",
        "- I am thinking confusion matrix but may be it's just me!\n",
        "- ..."
      ],
      "metadata": {
        "id": "xfTCrCc0a495"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_predictions(model, dataset, src_tokenizer, trg_tokenizer, out_file_path, device, batch_size=32):\n",
        "    \"\"\"\n",
        "    Generate predictions for a dataset and save them to a file\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "\n",
        "    # Open output file\n",
        "    with open(out_file_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"Source\\tTarget\\tPrediction\\n\")\n",
        "\n",
        "        # Process batches\n",
        "        for src, trg in tqdm(dataloader, desc=\"Generating predictions\"):\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "            # Generate predictions\n",
        "            predictions = model.predict(src, trg_tokenizer, device)\n",
        "\n",
        "            # Convert batch items to text\n",
        "            for i in range(len(src)):\n",
        "                # Process source\n",
        "                src_tokens = []\n",
        "                for idx in src[i].cpu().numpy():\n",
        "                    if idx != 0:  # Not padding\n",
        "                        src_tokens.append(list(src_tokenizer.word_index.keys())[list(src_tokenizer.word_index.values()).index(idx)])\n",
        "                src_text = ''.join(src_tokens)\n",
        "\n",
        "                # Process target\n",
        "                trg_tokens = []\n",
        "                for idx in trg[i][1:].cpu().numpy():  # Skip <sos> token\n",
        "                    if idx != 0:  # Not padding\n",
        "                        token = list(trg_tokenizer.word_index.keys())[list(trg_tokenizer.word_index.values()).index(idx)]\n",
        "                        if token == '</s>':  # End of sequence\n",
        "                            break\n",
        "                        trg_tokens.append(token)\n",
        "                trg_text = ''.join(trg_tokens)\n",
        "\n",
        "                # Process prediction\n",
        "                pred_tokens = []\n",
        "                for idx in predictions[i].cpu().numpy():\n",
        "                    if idx == 0 or idx == trg_tokenizer.word_index['</s>']:  # Padding or EOS\n",
        "                        break\n",
        "                    pred_tokens.append(list(trg_tokenizer.word_index.keys())[list(trg_tokenizer.word_index.values()).index(idx)])\n",
        "                pred_text = ''.join(pred_tokens)\n",
        "\n",
        "                # Write to file\n",
        "                f.write(f\"{src_text}\\t{trg_text}\\t{pred_text}\\n\")\n",
        "\n",
        "    print(f\"Predictions saved to {out_file_path}\")\n"
      ],
      "metadata": {
        "id": "LTtYsUrJ9skm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_write(\n",
        "    batch_size=64,\n",
        "    max_sequence_length=30,\n",
        "    emb_dim=32,\n",
        "    enc_hidden_dim=512,\n",
        "    dec_hidden_dim=512,\n",
        "    enc_layers=2,\n",
        "    dec_layers=2,\n",
        "    dropout=0.2,\n",
        "    cell_type='gru',\n",
        "    n_epochs=30,\n",
        "    lr=0.0001,\n",
        "    use_attention=False,\n",
        "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "):\n",
        "    print(f\"Training with attention: {use_attention}\")\n",
        "    train_data, dev_data, test_data = load_english_data()\n",
        "    X_train, y_train, X_dev, y_dev, X_test, y_test, src_tokenizer, trg_tokenizer = preprocess_data(\n",
        "        train_data, dev_data, test_data, max_sequence_length)\n",
        "\n",
        "    train_loader = DataLoader(Seq2SeqDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "    dev_loader = DataLoader(Seq2SeqDataset(X_dev, y_dev), batch_size=batch_size)\n",
        "    test_loader = DataLoader(Seq2SeqDataset(X_test, y_test), batch_size=batch_size)\n",
        "\n",
        "    input_dim = len(src_tokenizer.word_index) + 1\n",
        "    output_dim = len(trg_tokenizer.word_index) + 1\n",
        "\n",
        "    encoder = Encoder(input_dim, emb_dim, enc_hidden_dim, enc_layers, cell_type, dropout)\n",
        "    decoder = Decoder(output_dim, emb_dim, enc_hidden_dim, dec_hidden_dim, dec_layers, cell_type, dropout, use_attention)\n",
        "\n",
        "    model = Seq2Seq(encoder, decoder).to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "    best_valid_loss = float('inf')\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
        "        train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "        valid_loss, valid_acc = evaluate(model, dev_loader, criterion, device)\n",
        "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"Val Loss: {valid_loss:.4f} | Val Acc: {valid_acc:.4f}\")\n",
        "\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            torch.save(model.state_dict(), 'best_seq2seq_model.pt')\n",
        "            print(\"Model saved!\")\n",
        "\n",
        "    model.load_state_dict(torch.load('best_seq2seq_model.pt'))\n",
        "\n",
        "\n",
        "\n",
        "    # Generate and save predictions for test set\n",
        "    print(\"Generating predictions for test set...\")\n",
        "    test_dataset = Seq2SeqDataset(X_test, y_test)\n",
        "    generate_and_save_predictions(model, test_dataset, src_tokenizer, trg_tokenizer, 'test_predictions.tsv', device)\n",
        "\n",
        "    # Generate and save predictions for dev set\n",
        "    print(\"Generating predictions for dev set...\")\n",
        "    dev_dataset = Seq2SeqDataset(X_dev, y_dev)\n",
        "    generate_and_save_predictions(model, dev_dataset, src_tokenizer, trg_tokenizer, 'dev_predictions.tsv', device)\n",
        "\n",
        "    return model, src_tokenizer, trg_tokenizer\n"
      ],
      "metadata": {
        "id": "r-wFgTO8cXU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, src_tokenizer, trg_tokenizer = train_seq2seq_model_with_heatmaps(\n",
        "        batch_size=64,\n",
        "    max_sequence_length=30,\n",
        "    emb_dim=32,\n",
        "    enc_hidden_dim=512,\n",
        "    dec_hidden_dim=512,\n",
        "    enc_layers=2,  # Now we can have different values for encoder and decoder layers\n",
        "    dec_layers=2,\n",
        "    dropout=0.2,\n",
        "    cell_type='gru',\n",
        "    n_epochs=30,\n",
        "    lr=0.0001,\n",
        "        use_attention=False, # Changed to True for demonstration (otherwise we can't generate heatmaps)\n",
        "        num_samples_for_heatmap=10\n",
        "    )"
      ],
      "metadata": {
        "id": "YLB1cQW79z0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Question 5 (20 Marks)\n",
        "\n",
        "Now add an attention network to your basis sequence to sequence model and train the model again. For the sake of simplicity you can use a single layered encoder and a single layered decoder (if you want you can use multiple layers also). Please answer the following questions:\n",
        "\n",
        "(a) Did you tune the hyperparameters again? If yes please paste appropriate plots below.\n",
        "\n",
        "(b) Evaluate your best model on the test set and report the accuracy. Also upload all the predictions on the test set in a folder **predictions_attention** on your github project.\n",
        "\n",
        "(c) Does the attention based model perform better than the vanilla model? If so, can you check some of the errors that this model corrected and note down your inferences (i.e., outputs which were predicted incorrectly by your best seq2seq model are predicted correctly by this model)\n",
        "\n",
        "(d) In a 3 x 3 grid paste the attention heatmaps for 10 inputs from your test data (read up on what are attention heatmaps)."
      ],
      "metadata": {
        "id": "0YRbeDsHa8jp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_seq2seq_model_wandb(config=None):\n",
        "    with wandb.init(config=config):\n",
        "        config = wandb.config\n",
        "\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        train_data, dev_data, test_data = load_english_data()\n",
        "        X_train, y_train, X_dev, y_dev, X_test, y_test, src_tokenizer, trg_tokenizer = preprocess_data(\n",
        "            train_data, dev_data, test_data, config.max_sequence_length)\n",
        "\n",
        "        train_loader = DataLoader(Seq2SeqDataset(X_train, y_train), batch_size=config.batch_size, shuffle=True)\n",
        "        dev_loader = DataLoader(Seq2SeqDataset(X_dev, y_dev), batch_size=config.batch_size)\n",
        "        test_loader = DataLoader(Seq2SeqDataset(X_test, y_test), batch_size=config.batch_size)\n",
        "\n",
        "        input_dim = len(src_tokenizer.word_index) + 1\n",
        "        output_dim = len(trg_tokenizer.word_index) + 1\n",
        "\n",
        "        encoder = Encoder(\n",
        "            input_dim=input_dim,\n",
        "            emb_dim=config.emb_dim,\n",
        "            hidden_dim=config.hidden_dim,\n",
        "            n_layers=config.enc_layers,\n",
        "            cell_type=config.cell_type,\n",
        "            dropout=config.dropout\n",
        "        )\n",
        "        decoder = Decoder(\n",
        "            output_dim=output_dim,\n",
        "            emb_dim=config.emb_dim,\n",
        "            enc_hidden_dim=config.hidden_dim,\n",
        "            dec_hidden_dim=config.hidden_dim,\n",
        "            n_layers=config.dec_layers,\n",
        "            cell_type=config.cell_type,\n",
        "            dropout=config.dropout,\n",
        "            use_attention=True\n",
        "        )\n",
        "\n",
        "        model = Seq2Seq(encoder, decoder).to(device)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
        "        criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "\n",
        "        for epoch in range(config.n_epochs):\n",
        "            print(f\"Epoch {epoch+1}/{config.n_epochs}\")\n",
        "            train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "            valid_loss, valid_acc = evaluate(model, dev_loader, criterion, device)\n",
        "\n",
        "            print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "            print(f\"Val Loss: {valid_loss:.4f} | Val Acc: {valid_acc:.4f}\")\n",
        "\n",
        "            wandb.log({\n",
        "                'epoch': epoch + 1,\n",
        "                'train_loss': train_loss,\n",
        "                'train_acc': train_acc,\n",
        "                'val_loss': valid_loss,\n",
        "                'val_acc': valid_acc\n",
        "            })\n",
        "        wandb.finish()\n"
      ],
      "metadata": {
        "id": "T4ZGQkVWcYZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Question 6 (20 Marks)\n",
        "\n",
        "This a challenge question and most of you will find it hard.\n",
        "\n",
        "I like the visualisation in the figure captioned \"Connectivity\" in this [article](https://distill.pub/2019/memorization-in-rnns/#appendix-autocomplete). Make a similar visualisation for your model. Please look at this [blog](https://towardsdatascience.com/visualising-lstm-activations-in-keras-b50206da96ff) for some starter code. The goal is to figure out the following: When the model is decoding the $i$-th character in the output which is the input character that it is looking at?\n",
        "\n",
        "Have fun!\n"
      ],
      "metadata": {
        "id": "6pUsxVo6a_P2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xmaZ1KnWcY1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Question 7 (10 Marks)\n",
        "Paste a link to your github code for Part A\n",
        "\n",
        "Example: https://github.com/&lt;user-id&gt;/da6401_assignment3/partA;\n",
        "\n",
        "- We will check for coding style, clarity in using functions and a README file with clear instructions on training and evaluating the model (the 10 marks will be based on this).\n",
        "\n",
        "- We will also run a plagiarism check to ensure that the code is not copied (0 marks in the assignment if we find that the code is plagiarised).\n",
        "\n",
        "- We will check the number of commits made by the two team members and then give marks accordingly. For example, if we see 70% of the commits were made by one team member then that member will get more marks in the assignment (**note that this contribution will decide the marks split for the entire assignment and not just this question**).\n",
        "\n",
        "- We will also check if the training and test splits have been used properly. You will get 0 marks on the assignment if we find any cheating (e.g., adding test data to training data) to get higher accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "gSnrEA_0bDJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EGLYAZyJcZcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Question 8 (0 Marks)\n",
        "\n",
        "Note that this question does not carry any marks and will not be graded. This is only for students who are looking for a challenge and want to get something more out of the course.\n",
        "\n",
        "Your task is to finetune the GPT2 model to generate lyrics for English songs. You can refer to [this blog](https://towardsdatascience.com/natural-language-generation-part-2-gpt-2-and-huggingface-f3acb35bc86a) and follow the steps there. This blog shows how to finetune the GPT2 model to generate headlines for financial articles. Instead of headlines you will use lyrics so you may find the following datasets useful for training: [dataset1](https://data.world/datasets/lyrics), [dataset2](https://www.kaggle.com/paultimothymooney/poetry)\n",
        "\n",
        "At test time you will give it a prompt: \"I love Deep Learning\" and it should complete the song based on this prompt :-) Paste the generated song in a block below!"
      ],
      "metadata": {
        "id": "RvChaPTCbGIP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ccn5krpCcaEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self Declaration\n",
        "\n",
        "\n",
        "\n",
        "I, Name_XXX (Roll no: XXYY), swear on my honour that I have written the code and the report by myself and have not copied it from the internet or other students.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HSPz9XJZbNh4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qzf9vWSyaiJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRnIpDOTaHjR"
      },
      "outputs": [],
      "source": []
    }
  ]
}